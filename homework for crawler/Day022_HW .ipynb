{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 空氣污染監測網 網路爬蟲實作練習\n",
    "\n",
    "\n",
    "* 能夠利用 selenium + BeautifulSoup 撰寫爬蟲，並存放到合適的資料結構\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "根據範例 ，完成以下問題：\n",
    "\n",
    "* ① 取出 台北市士林區 2018/01 – 2018/08 的 SO2 資料\n",
    "* ② 取出 台北市士林區 2018/01 – 2018/08 的 SO2、CO 資料\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① 取出 台北市士林區 2018/01 – 2018/08 的 SO2 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/01    1.80\n",
      "2018/02    1.90\n",
      "2018/03    2.20\n",
      "2018/04    2.30\n",
      "2018/05    3.10\n",
      "2018/06    2.70\n",
      "2018/07    2.20\n",
      "2018/08    2.40\n",
      "Name: SO2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 打開瀏覽器\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "browser = webdriver.Chrome(executable_path='chromedriver')\n",
    "browser.get(\"http://taqm.epa.gov.tw/taqm/tw/MonthlyAverage.aspx\")\n",
    "\n",
    "# 模擬使用者操作行為，選擇/點擊\n",
    "selectSite = Select(browser.find_element_by_id(\"ctl05_ddlSite\"))\n",
    "selectSite.select_by_value('11')\n",
    "selectYear = Select(browser.find_element_by_id(\"ctl05_ddlYear\"))\n",
    "selectYear.select_by_value('2018')\n",
    "browser.find_element_by_id('ctl05_btnQuery').click()\n",
    "\n",
    "# 取得資料\n",
    "import time\n",
    "time.sleep(10) # 10秒後會關掉瀏覽器\n",
    "\n",
    "html_source = browser.page_source\n",
    "soup = BeautifulSoup(html_source, \"html5lib\")\n",
    "table = soup.find('table', class_='TABLE_G')\n",
    "\n",
    "# 關閉瀏覽器\n",
    "browser.quit()\n",
    "\n",
    "data = {}\n",
    "key = ''\n",
    "date = ''\n",
    "items = table.find_all('td')\n",
    "for item in items:\n",
    "    if 'style' in item.attrs:\n",
    "        key = item.text\n",
    "        data[key]={}\n",
    "    elif 'class' not in item.attrs:\n",
    "        if item.text.strip() != '':\n",
    "            if '/' in item.text:\n",
    "                date = item.text\n",
    "            else:\n",
    "                data[key][date] = item.text\n",
    "# print(data) # 取出所有資料\n",
    "\n",
    "import pandas as pd\n",
    "all_data = pd.DataFrame(data)[:-1]\n",
    "all_data = pd.DataFrame(data)[:-1]\n",
    "print(all_data[:8]['SO2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② 取出 台北市士林區 2018/01 – 2018/08 的 SO2、CO 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          SO2    CO\n",
      "2018/01  1.80  0.34\n",
      "2018/02  1.90  0.44\n",
      "2018/03  2.20  0.40\n",
      "2018/04  2.30  0.38\n",
      "2018/05  3.10  0.34\n",
      "2018/06  2.70  0.29\n",
      "2018/07  2.20  0.21\n",
      "2018/08  2.40  0.30\n"
     ]
    }
   ],
   "source": [
    "print(all_data[:8][['SO2', 'CO']]) # 補上CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "其他寫法:\n",
    "\n",
    "# 打開瀏覽器\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "browser = webdriver.Chrome(executable_path='chromedriver')\n",
    "browser.get(\"http://taqm.epa.gov.tw/taqm/tw/MonthlyAverage.aspx\")\n",
    "\n",
    "# 模擬使用者操作行為，選擇/點擊\n",
    "selectSite = Select(browser.find_element_by_id(\"ctl05_ddlSite\"))\n",
    "selectSite.select_by_value('11')\n",
    "selectYear = Select(browser.find_element_by_id(\"ctl05_ddlYear\"))\n",
    "selectYear.select_by_value('2018')\n",
    "browser.find_element_by_id('ctl05_btnQuery').click()\n",
    "\n",
    "# 取得資料\n",
    "import time\n",
    "time.sleep(15) # 15秒後會關掉瀏覽器\n",
    "\n",
    "html_source = browser.page_source\n",
    "soup = BeautifulSoup(html_source, \"html5lib\")\n",
    "table = soup.find('table', class_='TABLE_G')\n",
    "\n",
    "# 關閉瀏覽器\n",
    "browser.quit()\n",
    "\n",
    "# 創建dictionary\n",
    "data = {}\n",
    "for tr in table.find_all('tr')[1:]: # 跳過column欄位項目\n",
    "    for i, td in enumerate(tr.find_all('td')):\n",
    "        if len(tr.find_all('td')) == 5:      # 有5個td(欄目) + 第一個月資料\n",
    "            if i == 0:     # 第一個td是監測項目\n",
    "                items = td.text\n",
    "                data.setdefault(items, {})      # {'項目名稱': {}}\n",
    "            if i == 2:     # 第一個月監測日期\n",
    "                date = td.text\n",
    "            if i == 3:     # 第一個監測值\n",
    "                value = td.text\n",
    "                data[items][date] = value     # 字典裡面還是字典，進行新增資料\n",
    "        if len(tr.find_all('td')) == 3:       # 有3個td為第二個月之後資料\n",
    "            if i == 0:\n",
    "                date = td.text\n",
    "            if i == 1:\n",
    "                value = td.text\n",
    "                data[items][date] = value\n",
    "                \n",
    "# print(data) # 取出所有data\n",
    "                \n",
    "import pandas as pd\n",
    "all_data = pd.DataFrame(data)[:-1]\n",
    "all_data = pd.DataFrame(data)[:-1]\n",
    "print(all_data[:8]['SO2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
